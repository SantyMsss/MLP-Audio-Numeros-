# üéôÔ∏è Clasificador de D√≠gitos por Audio con MLP

Proyecto de Inteligencia Artificial que implementa un clasificador de n√∫meros hablados (0-9) utilizando una Red Neuronal Multicapa (MLP) con TensorFlow/Keras.

## üìã Descripci√≥n

Este proyecto utiliza t√©cnicas de procesamiento de se√±ales de audio y aprendizaje profundo para reconocer d√≠gitos hablados en archivos de audio. El sistema extrae caracter√≠sticas MFCC (Mel-Frequency Cepstral Coefficients) de los audios y las utiliza para entrenar un modelo de red neuronal que puede clasificar n√∫meros del 0 al 9.

## üöÄ Caracter√≠sticas Principales

- ‚úÖ **Clasificaci√≥n de d√≠gitos del 0 al 9** en espa√±ol e ingl√©s
- ‚úÖ **Extracci√≥n de caracter√≠sticas MFCC** para representaci√≥n del audio
- ‚úÖ **Red Neuronal Multicapa (MLP)** con 5 capas y dropout
- ‚úÖ **Visualizaci√≥n de resultados** con gr√°ficos de precisi√≥n y p√©rdida
- ‚úÖ **An√°lisis espectral** con espectrogramas MFCC
- ‚úÖ **Predicci√≥n en tiempo real** con nuevos archivos de audio
- ‚úÖ **Soporte para m√∫ltiples formatos** de audio (WAV, M4A, MP3, etc.)

## üìÅ Estructura del Proyecto

```
MLP/
‚îú‚îÄ‚îÄ app.py                      # Script principal de entrenamiento
‚îú‚îÄ‚îÄ test_audio.py              # Script para probar el modelo con nuevos audios
‚îú‚îÄ‚îÄ create_test_audio.py       # Genera audio sint√©tico para pruebas
‚îú‚îÄ‚îÄ convert_m4a_to_wav.py      # Instrucciones para convertir formatos
‚îú‚îÄ‚îÄ mlp_digit_classifier.h5    # Modelo entrenado guardado
‚îú‚îÄ‚îÄ content/
‚îÇ   ‚îî‚îÄ‚îÄ digit_dataset/         # Dataset de entrenamiento (5000 archivos)
‚îú‚îÄ‚îÄ pruebas/                   # Carpeta para archivos de audio de prueba
‚îî‚îÄ‚îÄ README.md                  # Este archivo
```

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python 3.11**
- **TensorFlow 2.20.0** - Framework de deep learning
- **Keras 3.12.0** - API de alto nivel para redes neuronales
- **Librosa 0.11.0** - Procesamiento y an√°lisis de audio
- **NumPy 2.3.4** - Computaci√≥n num√©rica
- **Matplotlib 3.10.7** - Visualizaci√≥n de datos
- **Scikit-learn 1.7.2** - Preprocesamiento y divisi√≥n de datos

## üì¶ Instalaci√≥n

1. **Clonar o descargar el proyecto**

2. **Crear entorno virtual**
```powershell
python -m venv .venv
```

3. **Activar el entorno virtual**
```powershell
.\.venv\Scripts\Activate.ps1
```

4. **Instalar dependencias**
```powershell
pip install tensorflow librosa matplotlib scikit-learn pydub scipy
```

## üìä Dataset

El proyecto utiliza un dataset de 5000 archivos de audio de d√≠gitos hablados:
- **Formato**: WAV
- **Contenido**: N√∫meros del 0 al 9
- **Idiomas**: Espa√±ol e ingl√©s
- **Distribuci√≥n**: ~500 muestras por clase (balanceado)

### Estructura del Dataset:
```
content/digit_dataset/
‚îú‚îÄ‚îÄ zero_en_M_1.wav
‚îú‚îÄ‚îÄ one_es_F_1.wav
‚îú‚îÄ‚îÄ two_en_M_2.wav
‚îú‚îÄ‚îÄ ...
```

Los archivos deben contener el nombre del n√∫mero en su nombre de archivo (ej: "cero", "uno", "zero", "one", etc.)

## üéØ app.py - Script Principal de Entrenamiento

### Funcionalidad

Este script implementa todo el pipeline de entrenamiento del modelo:

#### 1. **Carga y Preprocesamiento de Datos**
```python
load_dataset(dataset_path)
```
- Busca recursivamente archivos `.wav` en el dataset
- Identifica el n√∫mero hablado desde el nombre del archivo
- Mapea nombres en espa√±ol e ingl√©s a valores num√©ricos (0-9)
- Procesa 4999 de 5000 archivos exitosamente

#### 2. **Extracci√≥n de Caracter√≠sticas MFCC**
```python
extract_mfcc_features(y, sr, n_mfcc=13)
```
- Extrae 13 coeficientes MFCC de cada audio
- Calcula la media de cada coeficiente a lo largo del tiempo
- Genera un vector de caracter√≠sticas de 13 dimensiones por audio

#### 3. **Arquitectura del Modelo MLP**
```python
create_mlp_model(input_shape=13, num_classes=10)
```

**Capas de la red:**
- **Capa 1**: Dense(256) + ReLU + Dropout(0.3)
- **Capa 2**: Dense(128) + ReLU + Dropout(0.3)
- **Capa 3**: Dense(64) + ReLU + Dropout(0.2)
- **Capa 4**: Dense(32) + ReLU
- **Capa 5**: Dense(10) + Softmax (salida)

**Total de par√°metros**: 47,146 (184.16 KB)

#### 4. **Configuraci√≥n de Entrenamiento**
- **Optimizador**: Adam
- **Funci√≥n de p√©rdida**: Sparse Categorical Crossentropy
- **M√©tricas**: Accuracy
- **Callbacks**: 
  - EarlyStopping (paciencia: 10 √©pocas)
  - ReduceLROnPlateau (reduce learning rate en mesetas)

#### 5. **Divisi√≥n de Datos**
- **Entrenamiento**: 60% (3,199 muestras)
- **Validaci√≥n**: 20% (800 muestras)
- **Prueba**: 20% (1,000 muestras)
- **Estratificaci√≥n**: S√≠ (mantiene proporci√≥n de clases)

#### 6. **Resultados del Entrenamiento**
- ‚úÖ **Precisi√≥n en validaci√≥n**: 100% (desde √©poca 48)
- ‚úÖ **Precisi√≥n en prueba**: 100%
- ‚úÖ **√âpocas totales**: 100
- ‚úÖ **Learning rate final**: 0.00025

#### 7. **Visualizaciones Generadas**
1. Gr√°fico de precisi√≥n (entrenamiento vs validaci√≥n)
2. Gr√°fico de p√©rdida (entrenamiento vs validaci√≥n)
3. Espectrograma MFCC de un audio de prueba
4. Predicci√≥n de ejemplo con nivel de confianza

#### 8. **Modelo Guardado**
```
mlp_digit_classifier.h5
```
Formato HDF5 compatible con TensorFlow/Keras

### Ejecuci√≥n

```powershell
python app.py
```

**Salida esperada:**
```
Cargando dataset...
Encontrados 5000 archivos de audio
Dataset cargado: 4999 muestras, 13 caracter√≠sticas
Entrenando modelo...
Epoch 100/100
Precisi√≥n en prueba: 1.0000
Modelo guardado como mlp_digit_classifier.h5
```

---

## üß™ test_audio.py - Script de Predicci√≥n

### Funcionalidad

Este script permite probar el modelo entrenado con nuevos archivos de audio:

#### 1. **Carga del Modelo Entrenado**
```python
model = keras.models.load_model(model_path)
```

#### 2. **Conversi√≥n de Formatos**
```python
convert_to_wav(audio_path)
```
- Detecta archivos que no son WAV
- Intenta convertir usando FFmpeg
- Soporta formatos: M4A, MP3, FLAC, OGG

#### 3. **Procesamiento de Audio**
- Carga el archivo con Librosa
- Convierte a mono si es est√©reo
- Extrae caracter√≠sticas MFCC (13 coeficientes)
- Normaliza las caracter√≠sticas

#### 4. **Predicci√≥n**
```python
prediction = model.predict(features)
```
- Genera probabilidades para cada clase (0-9)
- Identifica la clase con mayor probabilidad
- Calcula el nivel de confianza

#### 5. **Visualizaci√≥n Detallada**

**Gr√°fico 1: Forma de Onda**
- Muestra la amplitud del audio en el tiempo
- Duraci√≥n total del audio

**Gr√°fico 2: Coeficientes MFCC**
- Visualizaci√≥n del espectrograma MFCC
- 13 coeficientes a lo largo del tiempo

**Gr√°fico 3: Espectrograma de Frecuencias**
- An√°lisis espectral completo
- Frecuencias vs tiempo

#### 6. **Reporte de Resultados**
```
üéØ RESULTADO DE LA PREDICCI√ìN
üî¢ N√∫mero predicho: 8
üìä Confianza: 100.00%

üìà Probabilidades para cada clase:
  0:   0.00%
  1:   0.00%
  ...
  8: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100.00%
  9:   0.00%
```

### Ejecuci√≥n

```powershell
python test_audio.py
```

**Proceso:**
1. Busca archivos en la carpeta `pruebas/`
2. Lista todos los archivos encontrados
3. Procesa cada archivo secuencialmente
4. Muestra predicci√≥n y visualizaci√≥n para cada uno

### Formatos Soportados
- ‚úÖ WAV (nativo)
- ‚ö†Ô∏è M4A (requiere conversi√≥n)
- ‚ö†Ô∏è MP3 (requiere conversi√≥n)
- ‚ö†Ô∏è FLAC (requiere conversi√≥n)
- ‚ö†Ô∏è OGG (requiere conversi√≥n)

---

## üìà Resultados del Modelo

### M√©tricas de Rendimiento

| M√©trica | Valor |
|---------|-------|
| Precisi√≥n en Entrenamiento | 98.25% |
| Precisi√≥n en Validaci√≥n | 100% |
| Precisi√≥n en Prueba | 100% |
| P√©rdida Final | 0.0015 |
| Tiempo de Entrenamiento | ~5 minutos |

### Matriz de Confusi√≥n
El modelo alcanza **100% de precisi√≥n** en el conjunto de prueba, lo que significa:
- ‚úÖ Cero falsos positivos
- ‚úÖ Cero falsos negativos
- ‚úÖ Clasificaci√≥n perfecta para todas las clases

### Curvas de Aprendizaje
- La precisi√≥n de validaci√≥n alcanza 100% en la √©poca 48
- La p√©rdida de validaci√≥n converge a ~0.0015
- No se observa overfitting gracias al dropout

---

## üéì Conceptos T√©cnicos

### MFCC (Mel-Frequency Cepstral Coefficients)
Los MFCC son caracter√≠sticas que representan el espectro de potencia a corto plazo de un sonido, bas√°ndose en una transformaci√≥n de coseno lineal de un espectro de potencia logar√≠tmica en una escala de frecuencia mel no lineal.

**¬øPor qu√© MFCC?**
- Imita la percepci√≥n auditiva humana
- Reduce la dimensionalidad del audio
- Captura caracter√≠sticas fon√©ticas importantes
- Robusto ante variaciones de tono

### Red Neuronal Multicapa (MLP)
Una MLP es una red neuronal feedforward que consiste en al menos tres capas de nodos: una capa de entrada, una o m√°s capas ocultas y una capa de salida.

**Ventajas para clasificaci√≥n de audio:**
- Aprende representaciones no lineales
- Maneja datos de alta dimensionalidad
- Generaliza bien con suficiente regularizaci√≥n

### Dropout
T√©cnica de regularizaci√≥n que desactiva aleatoriamente neuronas durante el entrenamiento para prevenir overfitting.

**En este modelo:**
- 30% en las primeras capas
- 20% en las capas intermedias
- Mejora la generalizaci√≥n

---

## üöÄ Uso Pr√°ctico

### Entrenar el Modelo

```powershell
# Activar entorno virtual
.\.venv\Scripts\Activate.ps1

# Ejecutar entrenamiento
python app.py
```

### Probar con Nuevo Audio

1. **Grabar o obtener un audio**
   - Di un n√∫mero del 0 al 9
   - Guarda como archivo de audio

2. **Convertir a WAV (si es necesario)**
   - Usar herramienta online: https://convertio.co/es/m4a-wav/
   - O con VLC: Media > Convert/Save > Audio - CD

3. **Colocar en carpeta pruebas**
```powershell
# Copiar archivo
Copy-Item "ruta/al/audio.wav" "pruebas/"
```

4. **Ejecutar predicci√≥n**
```powershell
python test_audio.py
```

5. **Ver resultados**
   - Terminal: N√∫mero predicho y confianza
   - Ventana emergente: Visualizaciones gr√°ficas

---

## üîß Soluci√≥n de Problemas

### Error: "No module named 'tensorflow'"
```powershell
pip install tensorflow librosa matplotlib scikit-learn
```

### Error: "No se encontr√≥ el dataset"
- Verifica que la carpeta `content/digit_dataset/` existe
- Aseg√∫rate de tener archivos WAV en el dataset
- Revisa la ruta en `app.py` l√≠nea 188

### Error: "Format not recognised" (archivos M4A)
- Convierte el audio a WAV antes de procesar
- Usa: https://convertio.co/es/m4a-wav/
- O instala FFmpeg y configura el PATH

### Precisi√≥n baja en tus audios
- Aseg√∫rate de que el audio sea claro
- Verifica que solo contenga el n√∫mero (sin ruido)
- Comprueba que la duraci√≥n sea similar al dataset (~1 segundo)
- Prueba con diferentes personas/acentos

---

## üìù Archivos Auxiliares

### create_test_audio.py
Genera un archivo WAV sint√©tico para pruebas r√°pidas sin necesidad de grabar.

```powershell
python create_test_audio.py
```

### convert_m4a_to_wav.py
Muestra instrucciones detalladas para convertir archivos M4A a WAV.

```powershell
python convert_m4a_to_wav.py
```

---

## üéØ Casos de Uso

1. **Sistemas de respuesta por voz (IVR)**
   - Men√∫s telef√≥nicos automatizados
   - Navegaci√≥n por comandos de voz

2. **Accesibilidad**
   - Entrada de datos por voz para personas con discapacidad
   - Control de dispositivos mediante voz

3. **Educaci√≥n**
   - Aplicaciones de aprendizaje de n√∫meros
   - Evaluaci√≥n autom√°tica de pronunciaci√≥n

4. **Dom√≥tica**
   - Control de dispositivos con comandos num√©ricos
   - Sistemas de seguridad con c√≥digo PIN por voz

---

## üë®‚Äçüíª Desarrollo

**Proyecto desarrollado como parte de:**
- Curso: Inteligencia Artificial
- UCEVA: ING SISTEMAS - Semestre 7
- Fecha: Noviembre 2025

### Tecnolog√≠as Implementadas:
- ‚úÖ Deep Learning (MLP)
- ‚úÖ Procesamiento de Se√±ales de Audio
- ‚úÖ Extracci√≥n de Caracter√≠sticas (MFCC)
- ‚úÖ Visualizaci√≥n de Datos
- ‚úÖ Regularizaci√≥n (Dropout)
- ‚úÖ Callbacks de Keras (EarlyStopping, ReduceLROnPlateau)

---

## üìÑ Licencia

Este proyecto es de c√≥digo abierto y est√° disponible para fines educativos.

---
- Presentado por:
- Laura Sofia Toro Garcia
- Santiago Martinez Serna
- Santiago Alejandro Santacruz

