# ğŸ™ï¸ Clasificador de DÃ­gitos por Audio con MLP

Proyecto de Inteligencia Artificial que implementa un clasificador de nÃºmeros hablados (0-9) utilizando una Red Neuronal Multicapa (MLP) con TensorFlow/Keras.

## ğŸ“‹ DescripciÃ³n

Este proyecto utiliza tÃ©cnicas de procesamiento de seÃ±ales de audio y aprendizaje profundo para reconocer dÃ­gitos hablados en archivos de audio. El sistema extrae caracterÃ­sticas MFCC (Mel-Frequency Cepstral Coefficients) de los audios y las utiliza para entrenar un modelo de red neuronal que puede clasificar nÃºmeros del 0 al 9.

## ğŸš€ CaracterÃ­sticas Principales

- âœ… **ClasificaciÃ³n de dÃ­gitos del 0 al 9** en espaÃ±ol e inglÃ©s
- âœ… **ExtracciÃ³n de caracterÃ­sticas MFCC** para representaciÃ³n del audio
- âœ… **Red Neuronal Multicapa (MLP)** con 5 capas y dropout
- âœ… **VisualizaciÃ³n de resultados** con grÃ¡ficos de precisiÃ³n y pÃ©rdida
- âœ… **AnÃ¡lisis espectral** con espectrogramas MFCC
- âœ… **PredicciÃ³n en tiempo real** con nuevos archivos de audio
- âœ… **Soporte para mÃºltiples formatos** de audio (WAV, M4A, MP3, etc.)

## ğŸ“ Estructura del Proyecto

```
MLP/
â”œâ”€â”€ app.py                      # Script principal de entrenamiento
â”œâ”€â”€ test_audio.py              # Script para probar el modelo con nuevos audios
â”œâ”€â”€ create_test_audio.py       # Genera audio sintÃ©tico para pruebas
â”œâ”€â”€ convert_m4a_to_wav.py      # Instrucciones para convertir formatos
â”œâ”€â”€ mlp_digit_classifier.h5    # Modelo entrenado guardado
â”œâ”€â”€ content/
â”‚   â””â”€â”€ digit_dataset/         # Dataset de entrenamiento (5000 archivos)
â”œâ”€â”€ pruebas/                   # Carpeta para archivos de audio de prueba
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.11**
- **TensorFlow 2.20.0** - Framework de deep learning
- **Keras 3.12.0** - API de alto nivel para redes neuronales
- **Librosa 0.11.0** - Procesamiento y anÃ¡lisis de audio
- **NumPy 2.3.4** - ComputaciÃ³n numÃ©rica
- **Matplotlib 3.10.7** - VisualizaciÃ³n de datos
- **Scikit-learn 1.7.2** - Preprocesamiento y divisiÃ³n de datos

## ğŸ“¦ InstalaciÃ³n

1. **Clonar o descargar el proyecto**

2. **Crear entorno virtual**
```powershell
python -m venv .venv
```

3. **Activar el entorno virtual**
```powershell
.\.venv\Scripts\Activate.ps1
```

4. **Instalar dependencias**
```powershell
pip install tensorflow librosa matplotlib scikit-learn pydub scipy
```

## ğŸ“Š Dataset

El proyecto utiliza un dataset de 5000 archivos de audio de dÃ­gitos hablados:
- **Formato**: WAV
- **Contenido**: NÃºmeros del 0 al 9
- **Idiomas**: EspaÃ±ol e inglÃ©s
- **DistribuciÃ³n**: ~500 muestras por clase (balanceado)

### Estructura del Dataset:
```
content/digit_dataset/
â”œâ”€â”€ zero_en_M_1.wav
â”œâ”€â”€ one_es_F_1.wav
â”œâ”€â”€ two_en_M_2.wav
â”œâ”€â”€ ...
```

Los archivos deben contener el nombre del nÃºmero en su nombre de archivo (ej: "cero", "uno", "zero", "one", etc.)

## ğŸ¯ app.py - Script Principal de Entrenamiento

### Funcionalidad

Este script implementa todo el pipeline de entrenamiento del modelo:

#### 1. **Carga y Preprocesamiento de Datos**
```python
load_dataset(dataset_path)
```
- Busca recursivamente archivos `.wav` en el dataset
- Identifica el nÃºmero hablado desde el nombre del archivo
- Mapea nombres en espaÃ±ol e inglÃ©s a valores numÃ©ricos (0-9)
- Procesa 4999 de 5000 archivos exitosamente

#### 2. **ExtracciÃ³n de CaracterÃ­sticas MFCC**
```python
extract_mfcc_features(y, sr, n_mfcc=13)
```
- Extrae 13 coeficientes MFCC de cada audio
- Calcula la media de cada coeficiente a lo largo del tiempo
- Genera un vector de caracterÃ­sticas de 13 dimensiones por audio

#### 3. **Arquitectura del Modelo MLP**
```python
create_mlp_model(input_shape=13, num_classes=10)
```

**Capas de la red:**
- **Capa 1**: Dense(256) + ReLU + Dropout(0.3)
- **Capa 2**: Dense(128) + ReLU + Dropout(0.3)
- **Capa 3**: Dense(64) + ReLU + Dropout(0.2)
- **Capa 4**: Dense(32) + ReLU
- **Capa 5**: Dense(10) + Softmax (salida)

**Total de parÃ¡metros**: 47,146 (184.16 KB)

#### 4. **ConfiguraciÃ³n de Entrenamiento**
- **Optimizador**: Adam
- **FunciÃ³n de pÃ©rdida**: Sparse Categorical Crossentropy
- **MÃ©tricas**: Accuracy
- **Callbacks**: 
  - EarlyStopping (paciencia: 10 Ã©pocas)
  - ReduceLROnPlateau (reduce learning rate en mesetas)

#### 5. **DivisiÃ³n de Datos**
- **Entrenamiento**: 60% (3,199 muestras)
- **ValidaciÃ³n**: 20% (800 muestras)
- **Prueba**: 20% (1,000 muestras)
- **EstratificaciÃ³n**: SÃ­ (mantiene proporciÃ³n de clases)

#### 6. **Resultados del Entrenamiento**
- âœ… **PrecisiÃ³n en validaciÃ³n**: 100% (desde Ã©poca 48)
- âœ… **PrecisiÃ³n en prueba**: 100%
- âœ… **Ã‰pocas totales**: 100
- âœ… **Learning rate final**: 0.00025

#### 7. **Visualizaciones Generadas**
1. GrÃ¡fico de precisiÃ³n (entrenamiento vs validaciÃ³n)
2. GrÃ¡fico de pÃ©rdida (entrenamiento vs validaciÃ³n)
3. Espectrograma MFCC de un audio de prueba
4. PredicciÃ³n de ejemplo con nivel de confianza

#### 8. **Modelo Guardado**
```
mlp_digit_classifier.h5
```
Formato HDF5 compatible con TensorFlow/Keras

### EjecuciÃ³n

```powershell
python app.py
```

**Salida esperada:**
```
Cargando dataset...
Encontrados 5000 archivos de audio
Dataset cargado: 4999 muestras, 13 caracterÃ­sticas
Entrenando modelo...
Epoch 100/100
PrecisiÃ³n en prueba: 1.0000
Modelo guardado como mlp_digit_classifier.h5
```

---

## ğŸ§ª test_audio.py - Script de PredicciÃ³n

### Funcionalidad

Este script permite probar el modelo entrenado con nuevos archivos de audio:

#### 1. **Carga del Modelo Entrenado**
```python
model = keras.models.load_model(model_path)
```

#### 2. **ConversiÃ³n de Formatos**
```python
convert_to_wav(audio_path)
```
- Detecta archivos que no son WAV
- Intenta convertir usando FFmpeg
- Soporta formatos: M4A, MP3, FLAC, OGG

#### 3. **Procesamiento de Audio**
- Carga el archivo con Librosa
- Convierte a mono si es estÃ©reo
- Extrae caracterÃ­sticas MFCC (13 coeficientes)
- Normaliza las caracterÃ­sticas

#### 4. **PredicciÃ³n**
```python
prediction = model.predict(features)
```
- Genera probabilidades para cada clase (0-9)
- Identifica la clase con mayor probabilidad
- Calcula el nivel de confianza

#### 5. **VisualizaciÃ³n Detallada**

**GrÃ¡fico 1: Forma de Onda**
- Muestra la amplitud del audio en el tiempo
- DuraciÃ³n total del audio

**GrÃ¡fico 2: Coeficientes MFCC**
- VisualizaciÃ³n del espectrograma MFCC
- 13 coeficientes a lo largo del tiempo

**GrÃ¡fico 3: Espectrograma de Frecuencias**
- AnÃ¡lisis espectral completo
- Frecuencias vs tiempo

#### 6. **Reporte de Resultados**
```
ğŸ¯ RESULTADO DE LA PREDICCIÃ“N
ğŸ”¢ NÃºmero predicho: 8
ğŸ“Š Confianza: 100.00%

ğŸ“ˆ Probabilidades para cada clase:
  0:   0.00%
  1:   0.00%
  ...
  8: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100.00%
  9:   0.00%
```

### EjecuciÃ³n

```powershell
python test_audio.py
```

**Proceso:**
1. Busca archivos en la carpeta `pruebas/`
2. Lista todos los archivos encontrados
3. Procesa cada archivo secuencialmente
4. Muestra predicciÃ³n y visualizaciÃ³n para cada uno

### Formatos Soportados
- âœ… WAV (nativo)
- âš ï¸ M4A (requiere conversiÃ³n)
- âš ï¸ MP3 (requiere conversiÃ³n)
- âš ï¸ FLAC (requiere conversiÃ³n)
- âš ï¸ OGG (requiere conversiÃ³n)

---

## ğŸ“ˆ Resultados del Modelo

### MÃ©tricas de Rendimiento

| MÃ©trica | Valor |
|---------|-------|
| PrecisiÃ³n en Entrenamiento | 98.25% |
| PrecisiÃ³n en ValidaciÃ³n | 100% |
| PrecisiÃ³n en Prueba | 100% |
| PÃ©rdida Final | 0.0015 |
| Tiempo de Entrenamiento | ~5 minutos |

### Matriz de ConfusiÃ³n
El modelo alcanza **100% de precisiÃ³n** en el conjunto de prueba, lo que significa:
- âœ… Cero falsos positivos
- âœ… Cero falsos negativos
- âœ… ClasificaciÃ³n perfecta para todas las clases

### Curvas de Aprendizaje
- La precisiÃ³n de validaciÃ³n alcanza 100% en la Ã©poca 48
- La pÃ©rdida de validaciÃ³n converge a ~0.0015
- No se observa overfitting gracias al dropout

---

## ğŸ“ Conceptos TÃ©cnicos

### MFCC (Mel-Frequency Cepstral Coefficients)
Los MFCC son caracterÃ­sticas que representan el espectro de potencia a corto plazo de un sonido, basÃ¡ndose en una transformaciÃ³n de coseno lineal de un espectro de potencia logarÃ­tmica en una escala de frecuencia mel no lineal.

**Â¿Por quÃ© MFCC?**
- Imita la percepciÃ³n auditiva humana
- Reduce la dimensionalidad del audio
- Captura caracterÃ­sticas fonÃ©ticas importantes
- Robusto ante variaciones de tono

### Red Neuronal Multicapa (MLP)
Una MLP es una red neuronal feedforward que consiste en al menos tres capas de nodos: una capa de entrada, una o mÃ¡s capas ocultas y una capa de salida.

**Ventajas para clasificaciÃ³n de audio:**
- Aprende representaciones no lineales
- Maneja datos de alta dimensionalidad
- Generaliza bien con suficiente regularizaciÃ³n

### Dropout
TÃ©cnica de regularizaciÃ³n que desactiva aleatoriamente neuronas durante el entrenamiento para prevenir overfitting.

**En este modelo:**
- 30% en las primeras capas
- 20% en las capas intermedias
- Mejora la generalizaciÃ³n

---

## ğŸš€ Uso PrÃ¡ctico

### Entrenar el Modelo

```powershell
# Activar entorno virtual
.\.venv\Scripts\Activate.ps1

# Ejecutar entrenamiento
python app.py
```

### Probar con Nuevo Audio

1. **Grabar o obtener un audio**
   - Di un nÃºmero del 0 al 9
   - Guarda como archivo de audio

2. **Convertir a WAV (si es necesario)**
   - Usar herramienta online: https://convertio.co/es/m4a-wav/
   - O con VLC: Media > Convert/Save > Audio - CD

3. **Colocar en carpeta pruebas**
```powershell
# Copiar archivo
Copy-Item "ruta/al/audio.wav" "pruebas/"
```

4. **Ejecutar predicciÃ³n**
```powershell
python test_audio.py
```

5. **Ver resultados**
   - Terminal: NÃºmero predicho y confianza
   - Ventana emergente: Visualizaciones grÃ¡ficas

---

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "No module named 'tensorflow'"
```powershell
pip install tensorflow librosa matplotlib scikit-learn
```

### Error: "No se encontrÃ³ el dataset"
- Verifica que la carpeta `content/digit_dataset/` existe
- AsegÃºrate de tener archivos WAV en el dataset
- Revisa la ruta en `app.py` lÃ­nea 188

### Error: "Format not recognised" (archivos M4A)
- Convierte el audio a WAV antes de procesar
- Usa: https://convertio.co/es/m4a-wav/
- O instala FFmpeg y configura el PATH

### PrecisiÃ³n baja en tus audios
- AsegÃºrate de que el audio sea claro
- Verifica que solo contenga el nÃºmero (sin ruido)
- Comprueba que la duraciÃ³n sea similar al dataset (~1 segundo)
- Prueba con diferentes personas/acentos

---

## ğŸ“ Archivos Auxiliares

### create_test_audio.py
Genera un archivo WAV sintÃ©tico para pruebas rÃ¡pidas sin necesidad de grabar.

```powershell
python create_test_audio.py
```

### convert_m4a_to_wav.py
Muestra instrucciones detalladas para convertir archivos M4A a WAV.

```powershell
python convert_m4a_to_wav.py
```

---

## ğŸ¯ Casos de Uso

1. **Sistemas de respuesta por voz (IVR)**
   - MenÃºs telefÃ³nicos automatizados
   - NavegaciÃ³n por comandos de voz

2. **Accesibilidad**
   - Entrada de datos por voz para personas con discapacidad
   - Control de dispositivos mediante voz

3. **EducaciÃ³n**
   - Aplicaciones de aprendizaje de nÃºmeros
   - EvaluaciÃ³n automÃ¡tica de pronunciaciÃ³n

4. **DomÃ³tica**
   - Control de dispositivos con comandos numÃ©ricos
   - Sistemas de seguridad con cÃ³digo PIN por voz

---

## ğŸ“Š Mejoras Futuras

- [ ] Implementar CNN o RNN para mejor rendimiento
- [ ] Agregar data augmentation (pitch shift, time stretch)
- [ ] Soportar frases numÃ©ricas ("veinte", "cien")
- [ ] Reconocimiento en tiempo real desde micrÃ³fono
- [ ] API REST para integraciÃ³n web
- [ ] AplicaciÃ³n mÃ³vil
- [ ] Soporte para mÃ¡s idiomas
- [ ] ReducciÃ³n de ruido automÃ¡tica
- [ ] DetecciÃ³n de voz activa (VAD)

---

## ğŸ‘¨â€ğŸ’» Desarrollo

**Proyecto desarrollado como parte de:**
- Curso: Inteligencia Artificial
- InstituciÃ³n: ING SISTEMAS - Semestre 7
- Fecha: Noviembre 2025

### TecnologÃ­as Implementadas:
- âœ… Deep Learning (MLP)
- âœ… Procesamiento de SeÃ±ales de Audio
- âœ… ExtracciÃ³n de CaracterÃ­sticas (MFCC)
- âœ… VisualizaciÃ³n de Datos
- âœ… RegularizaciÃ³n (Dropout)
- âœ… Callbacks de Keras (EarlyStopping, ReduceLROnPlateau)

---

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para fines educativos.

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork del repositorio
2. Crea una rama para tu feature
3. Commit de tus cambios
4. Push a la rama
5. Abre un Pull Request

---

## ğŸ“§ Contacto

Para preguntas o sugerencias sobre este proyecto, por favor contacta al desarrollador.

---

## ğŸ™ Agradecimientos

- Dataset de dÃ­gitos hablados de la comunidad open source
- Librosa por las herramientas de procesamiento de audio
- TensorFlow/Keras por el framework de deep learning
- Matplotlib por las visualizaciones

---

**Â¡Disfruta clasificando dÃ­gitos por audio! ğŸ™ï¸ğŸ¤–**
